<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Procedures on Good Fast</title>
    <link>https://blog.goodfast.info/categories/procedures/</link>
    <description>Recent content in Procedures on Good Fast</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Tue, 26 Sep 2017 08:31:17 +0200</lastBuildDate>
    <atom:link href="https://blog.goodfast.info/categories/procedures/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>How to use the transitive closure over a set of relations for fast path finding in SQL</title>
      <link>https://blog.goodfast.info/post/transitive-closures/</link>
      <pubDate>Tue, 26 Sep 2017 08:31:17 +0200</pubDate>
      
      <guid>https://blog.goodfast.info/post/transitive-closures/</guid>
      <description>

&lt;p&gt;In a &lt;a href=&#34;http://goodfast.info/post/speed-up-views-through-custom-materialization/&#34;&gt;previous post&lt;/a&gt;, I wrote about how we make sense of the world by modelling relationships between things as tree-like hierarchies.
This time we will add to this hierarchical data structure, a representation derived by calculating all possible paths.
This set of paths is referred to as a &lt;a href=&#34;https://en.wikipedia.org/wiki/Transitive_closurejj&#34;&gt;transitive closure&lt;/a&gt;, and can be thought of as the set of all paths if you start at each node in the tree.&lt;/p&gt;

&lt;p&gt;I wish I could tell you that it is as simple as Mr. Eby in &lt;a href=&#34;http://dirtsimple.org/2010/11/simplest-way-to-do-tree-based-queries.html&#34;&gt;this article&lt;/a&gt; makes it out to be, but
alas, when I got right down implementing a full solution, things got quite involved.
It tends to be like that.
None the less, credit where credit is due; go read that article first I can highly recommend it, and then come back here for more!&lt;/p&gt;

&lt;p&gt;I&amp;rsquo;ve developed the code for SQL Server, so it is immediately T-SQL compatible, but you can surely alter it for any decent database.&lt;/p&gt;

&lt;h2 id=&#34;background:594089c9c61d3c8bcdb4d6b1895da11a&#34;&gt;Background&lt;/h2&gt;

&lt;p&gt;Trees and hierarchies in general can get quite complicated, so why would we choose to add to this complexity yet another data structure?
The reason is so that we can apply &lt;a href=&#34;https://en.wikipedia.org/wiki/Memoization&#34;&gt;memoization&lt;/a&gt;; we buy time with space.
At the cost of the time to compute the transitive closure once, and the cost of the space required to persist it, we gain the time it would have taken to calculate it each time it is needed.&lt;/p&gt;

&lt;p&gt;Previously I wrote about how one can go about to materialize an entire complex and expensive view.
The use of the transitive closure can also be thought of as a kind of materialization, but it is far smarter and promises to be more useful.&lt;/p&gt;

&lt;p&gt;The [transitive] part in the name refers to a property that a relation can exhibit.
Since you are related to your father, and your child is related to you, your child is also related to your father.
We can say that the inheritance relation is transitive.
Since 9 &amp;gt; 5, and 5 &amp;gt; 3, it is also true that 9 &amp;gt; 5 &amp;gt; 3 and 9 &amp;gt; 3;
the &amp;ldquo;greater than&amp;rdquo; relation is transitive.&lt;/p&gt;

&lt;h2 id=&#34;representing-the-hierarchy:594089c9c61d3c8bcdb4d6b1895da11a&#34;&gt;Representing the hierarchy&lt;/h2&gt;

&lt;p&gt;The hierarchy we will work with is a simple one:&lt;/p&gt;


&lt;img srcset=&#34;../../ct_tree.svg&#34; src=&#34;../../ct_tree.png&#34; alt=&#34;Diagram of the tree with node a at root, nodes b and c below it, below node b is node d and e, below node c is node f, below node d is node g.&#34;&gt; 



&lt;p&gt;The usual way to represent such a hierarchy in a table is through self referencing records:&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;id&lt;/th&gt;
&lt;th&gt;parent_id&lt;/th&gt;
&lt;th&gt;label&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;&amp;lsquo;a&amp;rsquo;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;&amp;lsquo;b&amp;rsquo;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;3&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;&amp;lsquo;c&amp;rsquo;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;4&lt;/td&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;td&gt;&amp;rsquo;d&amp;rsquo;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;5&lt;/td&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;td&gt;&amp;lsquo;e&amp;rsquo;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;6&lt;/td&gt;
&lt;td&gt;3&lt;/td&gt;
&lt;td&gt;&amp;lsquo;f&amp;rsquo;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;7&lt;/td&gt;
&lt;td&gt;4&lt;/td&gt;
&lt;td&gt;&amp;lsquo;g&amp;rsquo;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;Such self referencing records in a single table makes manipulation of the hierarchy very simple.
For example, to move the sub tree rooted in node 2 and make it fall under node 6, we simply update the parent_id of node 2 to reference node 6.
This simplicity, however, comes at a cost.
When you want to traverse the hierarchy, you require iteration or recursion which is generally expensive.
This is especially so if all that you are after is only a portion of the tree, or worse, only the path from the root to a particular intermediate or leaf node.&lt;/p&gt;

&lt;p&gt;Suppose you want to find out the path from  node &amp;lsquo;g&amp;rsquo; to the root.
After finding the entry for node &amp;lsquo;g&amp;rsquo;, you have to repeatedly find the parent until there is no more parent.
Suppose you want to get the path from the root for each node in the tree.
The database has to do this process for every node.&lt;/p&gt;

&lt;p&gt;A transitive closure over all the relations in the base table gives you a ready-made set of paths which you can index and query, just like any other set of records.
No more need for recursive CTE&amp;rsquo;s each time you want path information, or worse still, multiple queries!&lt;/p&gt;

&lt;h2 id=&#34;setup:594089c9c61d3c8bcdb4d6b1895da11a&#34;&gt;Setup&lt;/h2&gt;

&lt;pre&gt;&lt;code class=&#34;language-SQL&#34;&gt;
-- create table node to represent the relations
create table node (id int, parent_id int, label varchar(50));

-- load noad
insert into node values 
(1,0,&#39;a&#39;),
(2,1,&#39;b&#39;),
(3,1,&#39;c&#39;),
(4,2,&#39;d&#39;),
(5,2,&#39;e&#39;),
(6,3,&#39;f&#39;),
(7,4,&#39;g&#39;);

-- table to hold the transitive closure over nodes
create table closure (parent_id int, child_id int, depth int, route varchar(100));
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Table node is the standard self referencing structure, and table closure will contain the paths that node represent.
Column node.label is only the label that applies to the particular node row, but column closure.route will contain a nice chain of all the labels from closure.parent_id to closure.child_id.
In a database that supports arrays, such as PostgreSQL, we can even go so far as to store the actual id values of the whole path.
In column closure.depth we want to store how many hops it takes to go from the node at parent_id to the node at child_id.&lt;/p&gt;

&lt;p&gt;What we want to achieve is to calculate all possible paths in the tree and represent them like this:&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;parent_id&lt;/th&gt;
&lt;th&gt;child_id&lt;/th&gt;
&lt;th&gt;depth&lt;/th&gt;
&lt;th&gt;route&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;a&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;b&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;a &amp;gt; b&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;3&lt;/td&gt;
&lt;td&gt;3&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;c&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;3&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;a &amp;gt; c&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;6&lt;/td&gt;
&lt;td&gt;6&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;f&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;3&lt;/td&gt;
&lt;td&gt;6&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;c &amp;gt; f&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;6&lt;/td&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;td&gt;a &amp;gt; c &amp;gt; f&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;4&lt;/td&gt;
&lt;td&gt;4&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;d&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;td&gt;4&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;b &amp;gt; d&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;4&lt;/td&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;td&gt;a &amp;gt; b &amp;gt; d&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;5&lt;/td&gt;
&lt;td&gt;5&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;e&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;td&gt;5&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;b &amp;gt; e&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;5&lt;/td&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;td&gt;a &amp;gt; b &amp;gt; e&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;7&lt;/td&gt;
&lt;td&gt;7&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;g&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;4&lt;/td&gt;
&lt;td&gt;7&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;d &amp;gt; g&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;td&gt;7&lt;/td&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;td&gt;b &amp;gt; d &amp;gt; g&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;7&lt;/td&gt;
&lt;td&gt;3&lt;/td&gt;
&lt;td&gt;a &amp;gt; b &amp;gt; d &amp;gt; g&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;Notice the identity paths, or paths starting and ending in the same node, with depth of zero.
Later on it will become apparent why we require these.&lt;/p&gt;

&lt;h3 id=&#34;closure-insert:594089c9c61d3c8bcdb4d6b1895da11a&#34;&gt;Closure insert&lt;/h3&gt;

&lt;p&gt;A new entry in table node can only be one of the following:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;a new, additional root - there exists no parent for it&lt;/li&gt;
&lt;li&gt;a new, additional child - there exists a parent for it&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;For either type of new node, table closure requires a new identity path.
Furthermore, if the new node has a parent, we also need to add entries for all paths ending in the new node.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-SQL&#34;&gt;create proc closure_insert @parent_id int, @child_id int, @route varchar(50) as 
begin
-- always insert identity
insert into closure (parent_id,child_id,depth,route) 
values (@child_id,@child_id,0, @route);
if  @parent_id &amp;lt;&amp;gt; @child_id and @parent_id is not null
insert into closure (parent_id,child_id,depth, route) 
select parent.parent_id, child.child_id,
parent.depth + child.depth + 1, 
parent.route + &#39; &amp;gt; &#39; + child.route 
from closure as parent cross join closure as child 
where parent.child_id = @parent_id and child.parent_id = @child_id;
end;
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;closure-delete:594089c9c61d3c8bcdb4d6b1895da11a&#34;&gt;Closure delete&lt;/h3&gt;

&lt;p&gt;Deleting a relation (suppose it is the node with id @child_id)from the node table requires us to delete all paths from the closure table that:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;start out from @child_id,&lt;/li&gt;
&lt;li&gt;end in @child_id,&lt;/li&gt;
&lt;li&gt;runs through @child_id, so any path that starts at any of @child_id&amp;rsquo;s parents,and any path that ends in any of @child_id&amp;rsquo;s children&lt;br /&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;pre&gt;&lt;code class=&#34;language-SQL&#34;&gt;create proc closure_delete @child_id int as begin
delete from link  
from closure as parent, closure as link, closure as child, closure as to_delete 
where 
parent.parent_id = link.parent_id and child.child_id = link.child_id
and parent.child_id = to_delete.parent_id and child.parent_id = to_delete.child_id
and (to_delete.child_id = @child_id or to_delete.parent_id = @child_id) 
and to_delete.depth &amp;lt; 2;
end;
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;closure-update:594089c9c61d3c8bcdb4d6b1895da11a&#34;&gt;Closure update&lt;/h3&gt;

&lt;p&gt;Similar to the delete operation, if a node changes, all paths that start from, or end in, or go through that node needs to be updated since the label of the node might have changed and thus the routes need to be built again.
If a node moved; if it is now a sub node of another node then all paths starting from, ending in and going through the node that moved needs to be deleted, and new paths added.&lt;/p&gt;

&lt;p&gt;To simplify matters we are going to delete all such starting from, ending in, and going through paths, and re-insert the individual nodes again in the correct order.
Before we delete all the paths we first will temporarily store all the nodes we will be re-inserting afresh after the delete.
Then we will do the delete, followed by successively calling the insert proc to insert everything again.&lt;/p&gt;

&lt;p&gt;But what if we insert a node (think add all paths involving this node) before we inserted the node&amp;rsquo;s parent(s)?
If you take a look at our insert proc you&amp;rsquo;ll see very quickly that this will result in problems; we will not find the parent paths, and thus add too few actual paths.
For this reason it is essential that we first insert all nodes without parents, then followed by the rest of the set that do have a parent, which will already be inserted.
The insert proc will take care of adding all required paths, but only if we insert in the correct order.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-SQL&#34;&gt;create proc closure_update @child_id int as begin
-- temp storage of nodes to insert after the deletion
declare @t as table (id int primary key, parent_id int, label varchar(50));

insert into @t (id,parent_id,label) 
select link.child_id,n.parent_id,n.label 
from closure as link join node as n on n.id = link.child_id
where  link.parent_id = @child_id;

delete from link 
from closure as link join @t as t
on link.child_id = t.id or link.child_id = @child_id;

-- repeatedly call the insert proc in the correct order, 
-- which is ensured by the recursive CTE over the set of nodes to insert
declare @_p int, @_c int, @_l varchar(50);
declare cur cursor fast_forward for 
with  to_insert as (
	select parent_id, id, label from @t
),  to_insert_ordered  as (
-- the anchor for the recursion
	select ti.parent_id, ti.id, ti.label 
	from to_insert as ti
	where ti.parent_id = 0
	or ti.id = @child_id
	or ti.parent_id not in (
		select id from to_insert
	)
	union all
	select ti.parent_id, ti.id, ti.label 
	from to_insert_ordered as tio
	join to_insert as ti
	on ti.parent_id = tio.id
) select parent_id, id, label from to_insert_ordered;
open cur;
fetch next from cur into @_p, @_c, @_l;
while @@FETCH_STATUS = 0 begin
	exec closure_insert @_p,@_c,@_l;
fetch next from cur into @_p, @_c, @_l;
end close cur deallocate cur;
end;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The insertion cursor query follows the usual pattern for a recursive CTE:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;establish the data to recurse over: to_insert&lt;/li&gt;
&lt;li&gt;establish the anchor, or starting point: to_insert_ordered&lt;/li&gt;
&lt;li&gt;union with a join onto itself and the whole list to_insert&lt;/li&gt;
&lt;li&gt;select the result&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&#34;closure-refresh:594089c9c61d3c8bcdb4d6b1895da11a&#34;&gt;Closure refresh&lt;/h3&gt;

&lt;p&gt;To do the initial load, and in case something goes wrong, we add one more proc; a full refresh proc, which is simply successive calls to the insert proc, but in the correct order as described in the previous section.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-SQL&#34;&gt;create proc closure_refresh as begin
truncate table closure;

declare @p int, @c int, @l varchar(50);
declare cur cursor fast_forward for with  to_insert as (
	select parent_id, id, label from node
),  to_insert_ordered  as (
	select ti.parent_id, ti.id, ti.label 
	from to_insert as ti
	where ti.parent_id = 0 or
	ti.parent_id not in (
		select id from to_insert
	)
	union all
	select ti.parent_id, ti.id, ti.label 
	from to_insert_ordered as tio
	join to_insert as ti
	on ti.parent_id = tio.id
) select parent_id, id, label from to_insert_ordered;
open cur;
fetch next from cur into @p, @c, @l;
while @@FETCH_STATUS = 0 begin
	exec closure_insert @p,@c,@l;
fetch next from cur into @p, @c, @l;
end close cur deallocate cur;
end;
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;testing:594089c9c61d3c8bcdb4d6b1895da11a&#34;&gt;Testing&lt;/h2&gt;

&lt;p&gt;Here are some sample queries which you can use to test your solution. I&amp;rsquo;ve done it, not going to paste 50 tables of output here, try all sorts and see what happens:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-SQL&#34;&gt;-- start clean
exec closure_refresh;
-- check that everything is in order
select * from closure;
-- relabel node 2
update node set label = &#39;z&#39; where id = 2;
-- do what the after update trigger will do:
exec closure_update 2;
-- not only node 2&#39;s identity entry, 
-- but all paths involving it should now say &#39;z&#39; instead of &#39;b&#39;
select * from closure;
-- fix node 2 again:
update node set label = &#39;b&#39; where id = 2;
exec closure_update 2;
-- things should be back to what it was initially...
select * from closure;
-- move node 2, or &#39;b&#39; under node 6
update node set parent_id = 6 where id = 2;
exec closure_update 2;
-- node 2 should now be under node 6
select * from closure;
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;go-forth-and-conquer:594089c9c61d3c8bcdb4d6b1895da11a&#34;&gt;Go forth and conquer!&lt;/h2&gt;

&lt;p&gt;Armed with the procedures we developed thus far, we can proceed to hook them up with after triggers on the node table.
When the node table change, the after triggers fire and the closure table stays up to date.&lt;/p&gt;

&lt;p&gt;When we want to answer questions such as, does there exist a path from X to Y, what is the longest path from X to Y (for obtaining the full path from the root), and many more such queries, we can simply perform fast selects against the closure table.
We can index parent_id, child_id, and (parent_id,child_id) and so on in order to speed things up.
We can create a few custom views for quickly determining all the paths from the roots to the individual intermediate and leaf nodes.&lt;/p&gt;

&lt;p&gt;The recursive CTE that is needed for the update procedure is unfortunate, but luckily it only operates on the set of nodes that need to change.
Unless you are altering root nodes all the time, this will generally be limited to a small number, and not the entire set of data as is the case in a full materialization of the whole tree.
This means that the maintenance overhead will generally be far less.&lt;/p&gt;

&lt;p&gt;This is only a proof of concept, but you can go forth from here and use it as a reference to implement more complex and advanced transitive closures.
I hope it helps you maintain performance on queries on hierarchies, and I hope you&amp;rsquo;ve learned something new along the way.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Wizen up a bit : solve problems bitwize</title>
      <link>https://blog.goodfast.info/post/wizen-up-a-bit/</link>
      <pubDate>Wed, 20 Sep 2017 08:31:17 +0200</pubDate>
      
      <guid>https://blog.goodfast.info/post/wizen-up-a-bit/</guid>
      <description>

&lt;p&gt;I&amp;rsquo;m rather obsessed with bits. All sorts of bits, at various times, but in particular, the digital bit of the Binary system. Notice the capitalization of &amp;ldquo;Binary&amp;rdquo; - it is intended.
Efficient bit representations of information is purity ; ever more compact representations elegance itself,
so for this post I invite you to come with me, way back to 2013, when a nice couple of  &lt;a href=&#34;https://en.wikipedia.org/wiki/Bitwise_operation&#34;&gt;bitwise&lt;/a&gt; operations flaunted their power and expressiveness.&lt;/p&gt;

&lt;p&gt;It&amp;rsquo;s tough for me when a value that will only ever require N distinct states gets over represented by vastly more bits than is needed.
A 4-byte integer to store a human age, a UUID, with it&amp;rsquo;s crazy 16 bytes, and the list goes on and on: we can do better!
Think of the real, actual small value, arriving inside the 64-bit CPU register, and the wasteful runs of zeros.
Think of it, happening billions and billions of times a second.
We can only hope that somewhere along the way, things get packed in a bit to mitigate those wasted runs of zeros.&lt;/p&gt;

&lt;p&gt;Once I read that using a short, or 2-byte database column type or variable is actually not more performant than just using a 4-byte integer.
Due to the fact that the smallest addressable space is anyways 4 bytes large, it took exactly the same resources to process 4, 2 or even a 1 byte word.
The exact context of that claim escapes me.
I put it down to my confirmation bias, operating sub consciously, blocking it out.
I like my confirmation bias working for me like that.&lt;/p&gt;

&lt;h2 id=&#34;the-back-story:d352b201a1938ed46d030d55323cc26d&#34;&gt;The back story&lt;/h2&gt;

&lt;p&gt;It was the weekend of the Google CodeJam qualifier.
Having heard of it some weeks before, I planned to check out the rules properly, and do some practice problems. It never happened.
Arriving home in the afternoon on the Saturday, I thought I did not have much of a chance at it due to the time constraint, but I could not help myself giving it a go anyways.
So it happened. Pacing around in my flat, beer in hand, I chose &lt;a href=&#34;https://code.google.com/codejam/contest/2270488/dashboard#s=p0&#34;&gt;this little problem&lt;/a&gt; to solve.
It was a sort of tic-tac-toe variant, but only the board state identifier part.&lt;/p&gt;

&lt;p&gt;Given a 4-x-4 board, determine if either player is in the winning position, or if a tie occurred.
The &amp;rsquo;T&amp;rsquo; symbol being neutral in that it could count in either player&amp;rsquo;s favor.&lt;/p&gt;

&lt;p&gt;Yes, you can loop over the elements or throw a Linq expression at it, but hey, we can have more fun than that, with bit masks and bit shifts.
This was bit mask land, and I was in my element!
For more details about the problem, visit the &lt;a href=&#34;https://code.google.com/codejam/contest/2270488/dashboard#s=p0&#34;&gt;problem statement&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&#34;bit-boards:d352b201a1938ed46d030d55323cc26d&#34;&gt;Bit boards&lt;/h2&gt;

&lt;p&gt;We choose an integer, 4 bytes, to store a bit mask of the player O, player X, how a column looks, how each of the two diagonals look and so on. We could have used a 2-byte unsigned  short instead of an int, sadly we didn&amp;rsquo;t. Well, got to leave something for next time.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-C#&#34;&gt;        public static int column, diagonal1, diagonal2, fullboard;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;and&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-C#&#34;&gt;            int xboard = 0, oboard = 0, tboard = 0;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We assign the static patterns we&amp;rsquo;ll use for column, the two diagonals and the full board:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-C#&#34;&gt;            column = Convert.ToInt32(&amp;quot;1000100010001&amp;quot;, 2);
            diagonal1 = Convert.ToInt32(&amp;quot;1000010000100001&amp;quot;, 2);
            diagonal2 = Convert.ToInt32(&amp;quot;0001001001001000&amp;quot;, 2);
            fullboard = Convert.ToInt32(&amp;quot;1111111111111111&amp;quot;, 2);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;I&amp;rsquo;m not going to bother you with file IO, so we skip to where we set the X, O and T boards:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-C#&#34;&gt;                        xboard = StringBoardToBitBoard(line, &#39;X&#39;);
                        oboard = StringBoardToBitBoard(line, &#39;O&#39;);
                        tboard = StringBoardToBitBoard(line, &#39;T&#39;);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Function StringBoardToBitBoard does exactly what  you would imagine - it assigns a &amp;lsquo;1&amp;rsquo; in the bit position if the char occurs and a &amp;lsquo;0&amp;rsquo; otherwise - see below for the full program.&lt;/p&gt;

&lt;h2 id=&#34;decision-and-output:d352b201a1938ed46d030d55323cc26d&#34;&gt;Decision and output&lt;/h2&gt;

&lt;pre&gt;&lt;code class=&#34;language-C#&#34;&gt;                        if (Won(xboard, tboard))
                            sw.WriteLine(&amp;quot;Case #{0}: X won&amp;quot;, i);
                        else if (Won(oboard, tboard))
                            sw.WriteLine(&amp;quot;Case #{0}: O won&amp;quot;, i);
                        else if (((xboard | oboard | tboard) &amp;amp; fullboard) == fullboard)
                            sw.WriteLine(&amp;quot;Case #{0}: Draw&amp;quot;, i);
                        else
                            sw.WriteLine(&amp;quot;Case #{0}: Game has not completed&amp;quot;, i);
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;the-real-magic-bitwise-operators-and-shifts:d352b201a1938ed46d030d55323cc26d&#34;&gt;The real magic: bitwise operators and shifts&lt;/h2&gt;

&lt;p&gt;And finally, let&amp;rsquo;s have a look at the elegant part; function Won and friends:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-C#&#34;&gt;        public static bool Won(int board, int tboard)
        {
            board |= tboard;  // apply the T position
            return LinesMatch(board) || ColumnsMatch(board) || DiagonalsMatch(board);
        }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;makes sense doesn&amp;rsquo;t it; you win if you have a line, a column or a diagonal.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-C#&#34;&gt;        public static bool LinesMatch(int board)
        {
            return board == (board | 15)
                || board == (board | (15 &amp;lt;&amp;lt; 4))
                || board == (board | (15 &amp;lt;&amp;lt; 8))
                || board == (board | (15 &amp;lt;&amp;lt; 12));
        }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;You have a lines match if your board position
is logical OR-ed (the &amp;lsquo;|&amp;rsquo; operator)  with any of the line representations, and still is equal to itself.
For the 4 line representations we could have used constants, to avoid the bit shift (&amp;rsquo;&amp;lt;&amp;lt;&amp;lsquo;) but defining them; that would be too laborious, but would probably have been better.
Also, the 15 magic number in there, for the first lines representation; should really live in a constant.&lt;/p&gt;

&lt;p&gt;In the same way, but slightly different, the columns and diagonals are checked:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-C#&#34;&gt;        public static bool ColumnsMatch(int board)
        {
            return
                board == (board | column)
                || board == (board | (column &amp;lt;&amp;lt; 1))
                || board == (board | (column &amp;lt;&amp;lt; 2))
                || board == (board | (column &amp;lt;&amp;lt; 3));
        }
        public static bool DiagonalsMatch(int board)
        {
            return board == (board | diagonal1)
                || board == (board | diagonal2);
        }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The diagonals checking could have happened all at once, why is this possible?&lt;/p&gt;

&lt;h2 id=&#34;conclusion:d352b201a1938ed46d030d55323cc26d&#34;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;Well, contrary to the confusion to what a casual glance of the code might  evoke in you, it&amp;rsquo;s really not terribly convoluted, but possibly slightly so.
The heart of the program is only one loop over the input set, while the win checking is a small constant set of finite bit operations, and bit operations can definitely be implemented as single machine instructions.
It surely ran fast on the small and large inputs, and so this question I got right.&lt;/p&gt;

&lt;p&gt;Not realizing that one only needed to get some of the problems correct in order to qualify for the actual contest, I happily shut down my computer and went to sleep.
Yay, I managed to do one of the CodeJam qualifier challenges, but there were no time to do all of them!
The next week when I realized my mistake, I was upset. I just had to get one or two more right and I could possibly have qualified!&lt;/p&gt;

&lt;p&gt;Less is more.  The saxophonist  &lt;a href=&#34;https://en.wikipedia.org/wiki/Jan_Garbarek&#34;&gt;Jan Garbarek&lt;/a&gt; has been credited with his &amp;ldquo;generous use of silence&amp;rdquo;.
I like that. May it be that, when people survey our code and data representations, may it be that they would reflect upon how few bits was used, or how few lines of code were written&amp;hellip;&lt;/p&gt;

&lt;h2 id=&#34;full-program:d352b201a1938ed46d030d55323cc26d&#34;&gt;Full program&lt;/h2&gt;

&lt;pre&gt;&lt;code class=&#34;language-C#&#34;&gt;using System;
using System.IO;
using System.Collections.Generic;
using System.Linq;
using System.Text;
using System.Threading.Tasks;

namespace ConsoleApplication1
{
    class Program
    {
        public static int column, diagonal1, diagonal2, fullboard;

        static void Main(string[] args)
        {
            column = Convert.ToInt32(&amp;quot;1000100010001&amp;quot;, 2);
            diagonal1 = Convert.ToInt32(&amp;quot;1000010000100001&amp;quot;, 2);
            diagonal2 = Convert.ToInt32(&amp;quot;0001001001001000&amp;quot;, 2);
            fullboard = Convert.ToInt32(&amp;quot;1111111111111111&amp;quot;, 2);

            int xboard = 0, oboard = 0, tboard = 0;

            try
            {
                string infile = &amp;quot;A-large.in&amp;quot;, outfile = &amp;quot;A-large.out&amp;quot;, line = &amp;quot;&amp;quot;;
                using (StreamReader sr = new StreamReader(infile))
                {
                    using (StreamWriter sw = new StreamWriter(outfile))
                    {
                    int numberOfProblems = Int32.Parse(sr.ReadLine());
                    for (int i = 1; i &amp;lt;= numberOfProblems; i++)
                    {
                        line = sr.ReadLine();
                        line += sr.ReadLine();
                        line += sr.ReadLine();
                        line += sr.ReadLine();

                        xboard = StringBoardToBitBoard(line, &#39;X&#39;);
                        oboard = StringBoardToBitBoard(line, &#39;O&#39;);
                        tboard = StringBoardToBitBoard(line, &#39;T&#39;);
                        if (Won(xboard, tboard))
                            sw.WriteLine(&amp;quot;Case #{0}: X won&amp;quot;, i);
                        else if (Won(oboard, tboard))
                            sw.WriteLine(&amp;quot;Case #{0}: O won&amp;quot;, i);
                        else if (((xboard | oboard | tboard) &amp;amp; fullboard) == fullboard)
                            sw.WriteLine(&amp;quot;Case #{0}: Draw&amp;quot;, i);
                        else
                            sw.WriteLine(&amp;quot;Case #{0}: Game has not completed&amp;quot;, i);

                        line = sr.ReadLine();
                    }
                    }
                    //Console.WriteLine(line);
                }
            }
            catch (Exception e)
            {

            }
        }

        public static bool Won(int board, int tboard)
        {
            board |= tboard;  // apply the T position
            return LinesMatch(board) || ColumnsMatch(board) || DiagonalsMatch(board);
        }
        public static bool LinesMatch(int board)
        {
            return board == (board | 15)
                || board == (board | (15 &amp;lt;&amp;lt; 4))
                || board == (board | (15 &amp;lt;&amp;lt; 8))
                || board == (board | (15 &amp;lt;&amp;lt; 12));
        }
        public static bool ColumnsMatch(int board)
        {
            return
                board == (board | column)
                || board == (board | (column &amp;lt;&amp;lt; 1))
                || board == (board | (column &amp;lt;&amp;lt; 2))
                || board == (board | (column &amp;lt;&amp;lt; 3));
        }
        public static bool DiagonalsMatch(int board)
        {
            return board == (board | diagonal1)
                || board == (board | diagonal2);
        }

        public static int StringBoardToBitBoard(string stringBoard, char oneChar)
        {
            string bitBoard = new String(stringBoard.Select(
                x =&amp;gt; x == oneChar ? &#39;1&#39; : &#39;0&#39;)
                .ToArray());
            return Convert.ToInt32(bitBoard, 2);
        }
    }
}

&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>Speed up slow views through custom materialization</title>
      <link>https://blog.goodfast.info/post/speed-up-views-through-custom-materialization/</link>
      <pubDate>Thu, 08 Jun 2017 08:31:17 +0200</pubDate>
      
      <guid>https://blog.goodfast.info/post/speed-up-views-through-custom-materialization/</guid>
      <description>

&lt;p&gt;SQL views are aluring as a means of abstraction; a &amp;ldquo;building block&amp;rdquo; to hide away commonly used complexity.
It is no wonder then that us developers will try them out, and before you know it, your clever recursive CTE view on that hierarchy is used everywhere, by everyone, but how is it affecting overall database performance&amp;hellip;&lt;/p&gt;

&lt;p&gt;They look like tables, can be joined on, selected from, and in some cases even updated just like tables, yet the reality is that they are not like tables.
So, you cannot consider a view to be a type of stored procedure, and you can also not consider a view to be a type of table or index; it is something in between.&lt;/p&gt;

&lt;p&gt;It is possible for the query planner to &amp;ldquo;reach into&amp;rdquo; a view, and discover which indexes to use in order to access information in the best way, but this quikcly breaks down once you perform any kind of complicated thing, such as a CTE, UNION statement, or anything else that breaks up the link from the source tables to the result set of the view.
When exactly you break this ability of the query planner to use appropriate indexes is a great idea for a future post - I have not found anything that directly states this as of yet.
Intuitivly  it makes sense that some kinds of data mangling will just make it impossible for the query planner to find indexes to use.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Note that it&#39;s of course always best to first inspect the query plan before concluding that a fiew is or is not making use of a particular index. I have made the mistake before of making grand statements on how poor the query planner is at choosing an index when dealing with a view, only to be shown that it in fact can do a bit more than what you might expect!
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;My goal in this post is simply to make you aware of the possability that complex views might be causing your database to perform sub optimally, and then to offer an in place, zero downtime solution to the problem.&lt;/p&gt;

&lt;h3 id=&#34;when-to-use-views:0d7721be2247c9da7d04dc0c01e0fcf2&#34;&gt;When to use views&lt;/h3&gt;

&lt;p&gt;The way I currently understand it,  you should use views when you want different &lt;em&gt;views&lt;/em&gt; on the same table, or simple connected set of tables; i.e. you want to include/exclude certain columns/rows, so in other words, as a means of information hiding, a means of performing restricted access to the information in the underlying tables; a different take on the same data.
It is debatable how many new systems are developed, that would choose to deligate security, access restriction type of functionality to the database, but there is a fair chance that it is happening out in the wild, since a recent SQL Server feature is row-level access, and data masking.&lt;/p&gt;

&lt;h3 id=&#34;discovering-the-problem:0d7721be2247c9da7d04dc0c01e0fcf2&#34;&gt;Discovering the problem&lt;/h3&gt;

&lt;p&gt;It was while I was performance tuning a very busy Azure Database, that I discovered a collection of particularly slow executing queries, spending most of their time in CPU.
The data volume involved could not account for the poor performance, being in the mere tens of thousands of small rows.
As far as I could determine, most of the appropriate indexes existed that would normally make things perform acceptably.
Something else was up&amp;hellip;&lt;/p&gt;

&lt;p&gt;Turning to the query plans, a pattern started emerging; slow, very slow views were joined on.
The views themselves were not very complex, but they did something interesting: they were recursive CTEs designed to traverse
a hierarchy, essentially a tree structure, and produce a full fan out of the entire tree.&lt;/p&gt;

&lt;h3 id=&#34;solution:0d7721be2247c9da7d04dc0c01e0fcf2&#34;&gt;Solution&lt;/h3&gt;

&lt;p&gt;My first inclination was to have SQL Server materialize these views for me. Materialized (or indexed) views is an &lt;a href=&#34;http://sqlmag.com/database-performance-tuning/introducing-indexed-views&#34;&gt;old feature of the server&lt;/a&gt;, dating back to SQL Server 2000 if I&amp;rsquo;m not mistaking, so surely in 2017 this should be completely possible.
Well, it turns out that in order for a view to be materialized, &lt;a href=&#34;https://docs.microsoft.com/en-us/sql/relational-databases/views/create-indexed-views&#34;&gt;a whole list of requirements&lt;/a&gt; need to be satisfied. For example, something as innocently looking as a LEFT JOIN in the view query would put a quick end to this solution path.&lt;br /&gt;
Researching it a bit further shed some light on why all these restrictions apply, but although it does make you be a bit more understanding, it still feels like this is something that should be possible, no matter how complex the view is.&lt;/p&gt;

&lt;p&gt;Completely redesigning the underlying hierarchical representation, with something like transative closures was not really an option, so the next best idea was to custom materialize these views.
The data access characteristics of the hierarchy and supporting tables was that they did not change all that often, yet they were queried all the time.
This was great news, since it meant that even if the materialization process took a bit of time, this would quickly be compensated for by the much, much faster query times.
Having the previously computed data now reside in a proper table also meant that it could be appropriately indexed, clustered, and even partitioned (although the volume was far too low for this need).&lt;/p&gt;

&lt;h4 id=&#34;the-procedure:0d7721be2247c9da7d04dc0c01e0fcf2&#34;&gt;The procedure&lt;/h4&gt;

&lt;ol&gt;
&lt;li&gt;Create a table (we&amp;rsquo;ll call it the Working) that structurally mirrors the result of querying the view (the View, later to be renamed to the Origin).&lt;/li&gt;
&lt;li&gt;Create a stored procedure (RefreshWorking) that will make use of Origin to refresh Working.&lt;/li&gt;
&lt;li&gt;Create AFTER triggers for all tables referenced by Origin, that will call RefreshWorking.&lt;/li&gt;
&lt;li&gt;Make the triggers intelligent in that they will only call RefreshWorking when the DML operation of the source table would actually affect the outcome of the Origin view.&lt;/li&gt;
&lt;li&gt;Optionally pass the source table name and the key values, through a table valued parameter to RefreshWorking, so that the procedure can more intelligently pick out which parts of Working will need refreshing.&lt;/li&gt;
&lt;li&gt;Create a view, CheckWorkingAndOrigin, that FULL JOIN view Origin and table Working, to ensure that they are identical.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Once all of this is done, it is time to test.
For your testing I can highly recommend &lt;a href=&#34;http://tsqlt.org/&#34;&gt;tSQLt&lt;/a&gt;; a completely T-SQL based unit testing system.
When you have assured yourself that RefreshWorking properly updates table Working, it is time for the deployment.&lt;/p&gt;

&lt;p&gt;In one transaction, rename  the original, slow view to Origin, create a synonym with the same name as the original slow view, and point the synonym at the Working table.
As the last step of the transaction, run RefreshWorking procedure so that the Working table will get properly updated and be primed for showtime.&lt;/p&gt;

&lt;h3 id=&#34;reward:0d7721be2247c9da7d04dc0c01e0fcf2&#34;&gt;Reward&lt;/h3&gt;

&lt;p&gt;After we implemented this procedure on a heavily queried complex view, we saw a query plan simplification going from
over 70 steps, to only 3 steps. More impressive is that the plan now took 481 times less CPU time!
The RefreshWorking procedure still called the original, slow, complex view, but it did this only when the source tables changed and in particular ways.
The procedure also minimized writes to the Working table, to prevent table locking for the heavy reading on it.&lt;/p&gt;

&lt;h3 id=&#34;summary:0d7721be2247c9da7d04dc0c01e0fcf2&#34;&gt;Summary&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;One way we make sense of the world is by modelling relationships between things as a tree-like hierarchy.&lt;/li&gt;
&lt;li&gt;Most database systems, however, are essentially flat when it comes to the most basic collection of storage; the table.&lt;/li&gt;
&lt;li&gt;We overcome the flatness in one particular way, the simpler  of possible ways, by representing the unbounded nested characteristic of hierarchies by self referencing records in a table.&lt;/li&gt;
&lt;li&gt;Self referencing records in a single table makes manipulation of the hierarchy a very simple operation, but this simplicity comes at a cost when you want to traverse the hierarchy.&lt;/li&gt;
&lt;li&gt;For traversing arbitrarily  deep hierarchies represented by self referencing records, you inevitably require recursion.&lt;/li&gt;
&lt;li&gt;Recursive CTEs break the essential link between the source tables and the view result set, making it impossible for the query planner to do anything but perform the entire process of the view&amp;rsquo;s query, even when you only desire a small subset.&lt;/li&gt;
&lt;li&gt;In the scenario where the source tables for the complex view are written to less than they are read from, you can optimize the complex view by materializing it into a concrete table.&lt;/li&gt;
&lt;li&gt;The materialized table can then be properly indexed for maximum query performance, at a relatively small index maintenance cost at write time.&lt;/li&gt;
&lt;li&gt;With this approach you are trading computation time for storage space.&lt;/li&gt;
&lt;li&gt;The writing of the materialized table happens on DML AFTER triggers, so that you first have the change written to the source tables before the materialized table is updated.&lt;/li&gt;
&lt;li&gt;Updating of the materialized table need not be a complete rewrite; the AFTER triggers can be programmed so that they only fire when columns that partake in the SELECT list for the origin view query change.&lt;/li&gt;
&lt;li&gt;A further optimization can be made where by the refresh stored procedure recieves a list of keys of rows that changed, and can then use this info to only update the materialized table where it actually needs to change.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;I hope that you will try out this procedure on slow views on your databases; it has really helped us a lot.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>